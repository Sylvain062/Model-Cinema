{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#///////////////////////\n",
    "# notebook des scores //////////////////////\n",
    "#///////////////////////////////////////////\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "os.chdir('D:\\Sylvain\\GitHub\\Model-Cinema')\n",
    "#***********************************************************************\n",
    "df=pd.read_csv('Data/allocineV5-SB.csv', sep=\",\", index_col = \"ID\")\n",
    "df2=pd.read_csv('Data/Archives/IMDB_PRO_star.csv', sep=\",\")\n",
    "df3=pd.read_csv('Data/Archives/Nom_imdbID_star.csv', sep=\",\")\n",
    "df6=pd.read_csv('Data/Archives/IMDB_PRO_director.csv', sep=\",\")\n",
    "df7=pd.read_csv('Data/Archives/Nom_imdbID_director.csv', sep=\",\")\n",
    "df8=pd.read_csv('Data/allocine_pers_1.csv', sep=\",\")\n",
    "df9=pd.read_csv('Data/allocine_pers_2.csv', sep=\",\")\n",
    "df10=pd.read_csv('Data/Archives/Actors_score.csv', sep=\",\")\n",
    "df11=pd.read_csv('Data/Archives/IMDB_ID_scrap_MF.csv', sep=\",\")\n",
    "\n",
    "# traitement du imbd_star\n",
    "df3 = df3.dropna(axis = 0, how = 'all', subset = ['star']) #' on enlève les lignes vides'\n",
    "df3['star']=df3['star'].replace('\\n', '', regex=True) # on enlève les \\n au début des noms de star\n",
    "df3['star']=df3['star'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df3['star']=df3['star'].apply(unidecode) #on enlève les accents\n",
    "# traitement du imbd_PRO_star\n",
    "df2 = df2.dropna(axis = 0, how = 'all', subset = ['Acteur']) #' on enlève les lignes vides'\n",
    "df2['Acteur']=df2['Acteur'].replace('\\n', '', regex=True) # on enlève les \\n au début des noms de star\n",
    "df2['Acteur']=df2['Acteur'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df2['Acteur']=df2['Acteur'].apply(unidecode) #on enlève les accents\n",
    "# traitement du imbd_director\n",
    "df7 = df7.dropna(axis = 0, how = 'all', subset = ['director']) #' on enlève les lignes vides'\n",
    "df7['director']=df7['director'].replace('\\n', '', regex=True) # on enlève les \\n au début des noms de star\n",
    "df7['director']=df7['director'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df7['director']=df7['director'].apply(unidecode) #on enlève les accents\n",
    "# traitement du imbd_PRO_director\n",
    "df6 = df6.dropna(axis = 0, how = 'all', subset = ['Director']) #' on enlève les lignes vides'\n",
    "df6['Director']=df6['Director'].replace('\\n', '', regex=True) # on enlève les \\n au début des noms de star\n",
    "df6['Director']=df6['Director'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df6['Director']=df6['Director'].apply(unidecode) #on enlève les accents\n",
    "# traitement du actors_score\n",
    "df10 = df10.dropna(axis = 0, how = 'all', subset = ['nom']) #' on enlève les lignes vides'\n",
    "df10['nom']=df10['nom'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df10['nom']=df10['nom'].apply(unidecode) #on enlève les accents\n",
    "# traitement du IMDB_ID_scrap_MF\n",
    "df11 = df11.dropna(axis = 0, how = 'all', subset = ['star']) #' on enlève les lignes vides'\n",
    "df11['star']=df11['star'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df11['star']=df11['star'].apply(unidecode) #on enlève les accents\n",
    "# traitement du allocine_PERS_1 et PERS_2\n",
    "df8=pd.concat([df8,df9])\n",
    "df8 = df8.dropna(axis = 0, how = 'all', subset = ['nom']) #' on enlève les lignes vides'\n",
    "df8['nom']=df8['nom'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df8['nom']=df8['nom'].apply(unidecode) #on enlève les accents\n",
    "\n",
    "#******** chargement et nettoyage du allname *\n",
    "#\"********************************************\n",
    "os.chdir('D:\\Sylvain\\Projet-data')\n",
    "df4 = pd.read_csv('ID_ALL_NAME.csv')\n",
    "df4 = df4.dropna(axis = 0, how = 'all', subset = ['primaryName']) #' on enlève les lignes vides'\n",
    "df4['primaryName']=df4['primaryName'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "df4['primaryName']=df4['primaryName'].apply(unidecode) #on enlève les accents\n",
    "\n",
    "# '##### ACTEURS #########################################################\n",
    "#*************************************************************************\n",
    "#on cree un DF avec tous les acteurs uniques du DF cible*******************************\n",
    "#**************************************************************************\n",
    "a1 = df['acteur_1']\n",
    "a2 = df['acteur_2']\n",
    "a3 = df['acteur_3']\n",
    "a4 = df['acteur_4']\n",
    "actors=pd.concat([a1,a2,a3,a4])\n",
    "actors=pd.DataFrame(actors,columns=['nom'])\n",
    "# 'suppression des NAN et doublons\n",
    "actors = actors.drop_duplicates(keep = 'first')\n",
    "actors = actors.dropna(axis = 0, how = 'any')\n",
    "actors['nom'] = actors['nom'].apply(unidecode) #suppression des accents'\n",
    "actors['nom'] = actors['nom'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "# '##### REALISATEURS #########################################################\n",
    "#*************************************************************************\n",
    "#on cree un DF avec tous les realisateurs uniques du DF cible*******************************\n",
    "#**************************************************************************\n",
    "a1 = df['real_1']\n",
    "a2 = df['real_2']\n",
    "a3 = df['real_3']\n",
    "directors=pd.concat([a1,a2,a3])\n",
    "directors=pd.DataFrame(directors,columns=['nom'])\n",
    "# 'suppression des NAN et doublons\n",
    "directors = directors.drop_duplicates(keep = 'first')\n",
    "directors = directors.drop_duplicates(subset ='nom',keep = 'first')\n",
    "directors = directors.dropna(axis = 0, how = 'any')\n",
    "directors['nom'] = directors['nom'].apply(unidecode) #suppression des accents'\n",
    "directors['nom'] = directors['nom'].str.replace(' ', '', regex=True) # on enlève tous les espaces\n",
    "# '##### SCENARISTES #########################################################\n",
    "#*************************************************************************\n",
    "#on cree un DF avec tous les scenaristes uniques du DF cible*******************************\n",
    "#**************************************************************************\n",
    "a1 = df['scen_1']\n",
    "a2 = df['scen_2']\n",
    "a3 = df['scen_3']\n",
    "scenaristes=pd.concat([a1,a2,a3])\n",
    "scenaristes=pd.DataFrame(scenaristes,columns=['nom'])\n",
    "# 'suppression des NAN et doublons\n",
    "scenaristes = scenaristes.drop_duplicates(keep = 'first')\n",
    "scenaristes = scenaristes.dropna(axis = 0, how = 'any')\n",
    "scenaristes['nom'] = scenaristes['nom'].apply(unidecode) #suppression des accents'\n",
    "scenaristes['nom'] = scenaristes['nom'].str.replace(' ', '', regex=True) # on enlève tous les espaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17037, 1)  actors\n",
      "(17037, 4)  actors2\n",
      "(17037, 6)  actors3\n",
      "(17037, 6)  actors3\n",
      "(17037, 15) actors4\n",
      "(17037, 6) actors_BDD_Fin\n"
     ]
    }
   ],
   "source": [
    "#*********************************************\n",
    "#******** on fait les merges ACTEURS *****************\n",
    "#*********************************************\n",
    "os.chdir('D:\\Sylvain\\GitHub\\Model-Cinema')\n",
    "#on part du fichier des acteurs qu'on merge avec acteurs score\n",
    "actors = actors.drop_duplicates(subset ='nom',keep = 'first')\n",
    "print(actors.shape,' actors')\n",
    "actors2 = pd.merge(actors, df10, left_on = 'nom', right_on = 'nom', how='left')\n",
    "print(actors2.shape,' actors2')\n",
    "actors2\n",
    "# # recupération des starmeter de Manon\n",
    "actors3 = pd.merge(actors2, df11, left_on = 'ID', right_on = 'ID', how='left')\n",
    "print(actors3.shape,' actors3')\n",
    "actors3['STARmeter_x']=actors3['STARmeter_x'].fillna(actors3['STARmeter_y'])\n",
    "print(actors3.shape,' actors3')\n",
    "# # recupération des recompenses, nb films et series, durée carriere\n",
    "actors4 = pd.merge(actors3, df8, left_on = 'nom', right_on = 'nom', how='left')\n",
    "actors4 = actors4.drop_duplicates(subset ='nom',keep = 'first')\n",
    "print(actors4.shape,'actors4')\n",
    "actors_BDD_Fin=actors4[['nom','ID_x','STARmeter_x','recompenses','carriere_duree','films_series']]\n",
    "actors_BDD_Fin=actors_BDD_Fin. rename(columns={'ID_x': 'ID','STARmeter_x':'STARmeter'})\n",
    "print(actors_BDD_Fin.shape,'actors_BDD_Fin')\n",
    "actors_BDD_Fin\n",
    "actors_BDD_Fin=  actors_BDD_Fin.add_suffix('_actors')\n",
    "actors_BDD_Fin.to_csv('Data/BDD_Fin_actors.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6785, 3) df13\n",
      "(6785, 6)  directors10\n",
      "(6785, 15)  directors11\n"
     ]
    }
   ],
   "source": [
    "#*********************************************\n",
    "#******** on fait les merges REALISATEURS *****************\n",
    "#*********************************************\n",
    "#dans le all name on ne garde que les réalisateurs\n",
    "os.chdir('D:\\Sylvain\\GitHub\\Model-Cinema')\n",
    "df12=pd.read_csv('Data/Archives/IMDB_PRO_director_MF.csv', sep=\",\")\n",
    "df13=pd.read_csv('Data/Archives/directors_ID_pour_scrap.csv', sep=\",\")\n",
    "print(df13.shape,'df13')\n",
    "#'on merge la base initiale avec les données scrappées de manon'\n",
    "directors10 = pd.merge(df13, df12, left_on = 'nom', right_on = 'director', how='left')\n",
    "print(directors10.shape,' directors10')\n",
    "\n",
    "# recupération des recompenses, nb films et series, durée carriere\n",
    "directors11 = pd.merge(directors10, df8, left_on = 'nom', right_on = 'nom', how='left')\n",
    "directors11 = directors11.drop_duplicates(subset ='nom',keep = 'first')\n",
    "print(directors11.shape,' directors11')\n",
    "\n",
    "directors11=directors11[['nom','ID_x','STARmeter','recompenses','carriere_duree','films_series']]\n",
    "directors11=directors11.rename(columns={'ID_x': 'ID','STARmeter':'STARmeter'})\n",
    "#on rajoute les suffixes\n",
    "directors11=  directors11.add_suffix('_directors')\n",
    "#'on sauvergarde\n",
    "directors11.to_csv('Data/BDD_Fin_directors.csv')\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11159, 1) scenaristes\n"
     ]
    }
   ],
   "source": [
    "#*********************************************\n",
    "#******** on fait les merges SCENARISTE *****************\n",
    "#*********************************************\n",
    "scenaristes = scenaristes.drop_duplicates(subset ='nom',keep = 'first')\n",
    "print(scenaristes.shape,'scenaristes')\n",
    "scenaristes2 = pd.merge(scenaristes, df8, left_on = 'nom', right_on = 'nom', how='left')\n",
    "scenaristes2\n",
    "scenaristes_BDD_Fin=scenaristes2[['nom','recompenses','carriere_duree','films_series']]\n",
    "scenaristes_BDD_Fin = scenaristes_BDD_Fin.drop_duplicates(subset ='nom',keep = 'first')\n",
    "#on rajoute les suffixes\n",
    "scenaristes_BDD_Fin=  scenaristes_BDD_Fin.add_suffix('_scenaristes')\n",
    "#'on sauvergarde\n",
    "scenaristes_BDD_Fin.to_csv('Data/BDD_Fin_scenaristes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
