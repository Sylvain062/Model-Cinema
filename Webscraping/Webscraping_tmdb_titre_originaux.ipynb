{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.themoviedb.org/movie/615656\n",
      "Le script a pris 0.653850793838501 secondes pour s'exécuter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titre</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, titre, budget]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Démarrage du chronomètre pour calculer la durée d'exécution du script\n",
    "start_time = time.time()\n",
    "\n",
    "# Importation du fichier CSV contenant les id\n",
    "df_id = pd.read_csv('Data/df_for_scrap_tmdb.csv')\n",
    "\n",
    "# Définition du nombre de requêtes effectuées en parallèle (Dépend du CPU)\n",
    "nombre_req = 12\n",
    "\n",
    "# Définition de la plage d'id à scraper\n",
    "id_in = 0\n",
    "id_out = 1\n",
    "id = id_in\n",
    "\n",
    "# Définition du chemin du fichier csv contenant les id\n",
    "path_out = f'Data/tmdb_titres_originaux_{id_in}_{id_out}.csv'\n",
    "\n",
    "# Définition de la variable initial pour pour suivre la progression\n",
    "pourcent = 0\n",
    "\n",
    "# Définition du HEADERS pour que les requetes ne soit pas bloquées\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582'}\n",
    "\n",
    "# Définition de la fonction pour scraper les données de TMDB\n",
    "def tmdb_titre_scrap(i):\n",
    "    global pourcent, id\n",
    "    id += 1\n",
    "\n",
    "    # Initialisation des variables pour les informations à récupérer\n",
    "    titre = budget = None\n",
    "    \n",
    "    try:\n",
    "        # Construction de l'URL pour chaque film basé sur son ID\n",
    "        url = f'https://www.themoviedb.org/movie/{i}'\n",
    "        print(url)\n",
    "        res = session.get(url, allow_redirects=True, headers=HEADERS)\n",
    "        # Print du % avec une intervalle de 72 tests\n",
    "        pourcent += 1\n",
    "        if pourcent == 72:\n",
    "            print('Execution :', round(((id-id_in)/(id_out-id_in))*100, 2), '%')\n",
    "            pourcent = 0\n",
    "        # Vérification du statut de la réponse, retourne des \"0\" si le code HTTP n'est pas 200 ou si l'URL a été redirigée\n",
    "        if res.status_code != 200:\n",
    "            return i, \"0\", \"0\"\n",
    "        \n",
    "        # Utilisation de BeautifulSoup pour parser le contenu HTML\n",
    "        soup = BeautifulSoup(res.content, 'lxml')\n",
    "        print(soup)\n",
    "        # Extraction de tout le contenu entre des balises <p>\n",
    "        p_tags = soup.find_all('p')\n",
    "\n",
    "        # Cherchez la balise <p> contenant le mot \"Budget\"\n",
    "        for p in p_tags:\n",
    "            if 'Budget' in p.text:\n",
    "                # Extrait le texte après \"Budget\"\n",
    "                budget = p.text.split('Budget')[-1].strip()\n",
    "\n",
    "        # Récupération du titre\n",
    "        titre_temp = soup.find('strong', text='Original Title')\n",
    "        if titre_temp:\n",
    "            titre = titre_temp.next_sibling.strip()\n",
    "        else:\n",
    "            titre_temp_2 = soup.find('title')\n",
    "            titre = titre_temp_2.get_text() if titre_temp_2 else ''\n",
    "            titre = titre.split('(')[0].strip()\n",
    "\n",
    "    # Gestion des exceptions liées aux requêtes HTTP\n",
    "    except requests.exceptions.RequestException:\n",
    "        return i, \"0\", \"0\"\n",
    "    \n",
    "    # Retourne les données extraites ou des \"0\" si les données ne sont pas disponibles\n",
    "    resultat = (\n",
    "        i,\n",
    "        titre if titre else \"0\",\n",
    "        budget if budget else \"0\",\n",
    "    )\n",
    "    return resultat\n",
    "\n",
    "# Initialisation d'un DataFrame pour stocker les données extraites   \n",
    "df = pd.DataFrame(columns=['id', 'titre', 'budget']) \n",
    "session = requests.Session()\n",
    "\n",
    "# Utilisation d'un ThreadPoolExecutor pour exécuter les scrapings en parallèle et utiliser les differents coeurs logique du PC.\n",
    "with ThreadPoolExecutor(max_workers=nombre_req) as executor:\n",
    "\n",
    "    # Soumission des tâches de scraping pour chaque ID de film entre 1 et la variable total_film\n",
    "    tests = [executor.submit(tmdb_titre_scrap, i) for i in df_id['id'][id_in:id_out]]\n",
    "    for test in tests:\n",
    "        i, titre, budget = test.result()\n",
    "        variables = (titre, budget)\n",
    "        if any(v != \"0\" for v in variables):\n",
    "            df.loc[i] = [i, titre, budget]\n",
    "\n",
    "# Arrêt du chronomètre et affichage de la durée d'exécution\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Le script a pris {execution_time} secondes pour s'exécuter.\")\n",
    "\n",
    "# Sauvegarde des résultats dans un fichier CSV\n",
    "df.to_csv(path_out, index=False)\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
